%&latex
\documentclass[11pt]{asaproc}

\usepackage{graphicx}

%\usepackage{mathtime}

%%UNCOMMENT following line if you have package
\usepackage{times}

\title{Number of Samples Needed For Model Selection With Confidence}

\author{Sean G. Carver\thanks{American University, 4400 Massachusetts
    Avenue NW, Washington DC, 20016}}
\begin{document}
\SweaveOpts{concordance=TRUE}


\maketitle

\begin{abstract}
  A common measure used to quantify the similarity of two models is
  the Kullback-Leibler divergence, computed from a true model to an
  alternative model. We propose a different measure: the number of
  samples needed to correctly reject the alternative model with a
  given confidence level (e.g. 95\%). Our method works as follows: (1)
  we simulate samples from the true model, (2) for each sample, we
  compute a log-likelihood ratio (3), we bootstrap and sum the
  log-likelihood ratios---when this sum is positive, we select the
  true model, (4) using simple linear regression, we determine the
  number of terms (i.e. number of samples) needed to make the desired
  quantile (e.g. 5\%) fall at zero. We have tested this method on
  t-distributions of different degrees of freedom and have confirmed
  that it gives reasonably consistent results. However, we plan to
  apply this method to Markov chains, e.g. used for sports statistics
  like tennis, volleyball, and baseball. For these applications, it
  may be desirable to have a measure that is easier to interpret than
  the Kullback-Leibler divergence. How many innings are needed to
  falsify the model of the Yankees when simulating a model of the
  Orioles?
\begin{keywords}
Model selection, likelihood ratio test, Akaike information criterion,
Kullback-Leibler divergence
\end{keywords}
\end{abstract}

\section{Motivation}
When working with two or more probabilistic models, you may want to
quantify their similarity.  Specifically, when observing simulations
of one model, can you easily tell that the simulations do not come
from another model?  Or do only subtle differences between the models
make this discernment difficult?

My favorite example involves baseball.  What if you had score cards
recording, play after play for many games, what bases had runners, and
how many outs had occurred.  Could you tell which teams were up at
bat?  In practice, there will be many uncontrolled factors, so if you
require a substantial degree of certainty, you will only be able to
distinguish between two mismatched teams.  On the other hand, in
theory, if the teams playing are {\em models of teams}, obeying
precisely defined and known probability laws, and if the models make
different, even slightly different, predictions, you can make the
choice confidently.  Indeed, you can have as high a chance as you
want, short of being absolutely certain, of choosing the right team,
provided you have enough data.  But how much data suffice for the
confidence you demand?

Once you derive a model of each team from game records, you can ask
yourself, for example: how similar is the model of the our home team,
the Baltimore Orioles, to the model one of their rivals, the New York
Yankees.  (Baltimore hosted the Joint Statistical Meetings in 2017.)
How many Baltimore-at-bat half-innings would you have to simulate to
correctly reject the statement that the model of the Yankees generated
the simulations, and get this answer right at least 95\% of the time
(or some other specified confidence level)?

\section{Baseball as a Markov Chain}
Baseball is often modeled as a Markov chain [references], where each
half-inning proceeds through a number of states.  The states record
which bases have runners, and how many outs have occurred.  There are
8 possible combinations of runners on base (labeled: 0, 1, 2, 3, 12,
13, 23, 123), and 4 possible numbers of outs (0-3, labeled with
repeated X's).  Specifically, the state label 0 indicates empty bases
with no outs, whereas the state label 123XX indicates loaded bases
with two outs, etc.  All states with three outs are combined into a
single absorbing state: XXX, which signifies the end of the
half-inning.  There exist a total of 25 states and a total of 600
(equaling $24 \times 25$) conceivable transitions.  We note that many
of these transitions remain impossible, by the rules of baseball, such
as, for example, going from bases empty with two outs, to bases empty
with one out, i.e.\ 0XX:0X.  Using a recursive algorithm savvy to the
rules, I counted 296 allowable transitions between states, and 304
illegal ones.

We can list the 25 states in any order, but we prefer to put the
absorbing state, XXX, last.  Then we can then define a $24 \times 25$
matrix of transition probabilities, with entries $\{p_{i:j}\}$.
Specifically, the entry $p_{i:j}$ is the probability that the team
will transition to state $j$, assuming it finds itself in state $i$,
just prior.  For instance, $p_{0XX:0X} = 0$, because, as explained
above, this transition cannot happen, by the rules of baseball.

On the main diagonal, where $i=j$, we have probabilities of
transitions from states back to themselves.  These transitions can
always occur, though sometimes they remain rare. For an example of a
less rare transition of this type, 0:0 occurs, for example, at the
beginning of a half-inning if the first play is a home run.  Other
transitions back to the same state happen much less frequently.  In
2011, no Major League team underwent the transition 1X:1X even though
it could have occurred, within the rules of the game.  Had a team
undergone this transition, the batter would have advanced only to
first base, while the runner on first would have scored---clearly an
unusual scenario, but not impossible, as demonstrated by the fact that
both 1:1 and 1XX:1XX did occur in 2011 Major League play.  There were
23 more allowable transitions that never occurred during the 2011
Major Leagues.

The last column of the matrix, with entries $p_{i:XXX}$, consists of
transitions from all states to the end of the inning---state XXX.  For
example, 123:XXX occurs with loaded bases and no outs when the
defending team makes a triple-play. Other transitions of this type,
such as 0:XXX, cannot legally happen under the rules---the
corresponding transition probabilities must remain zero.

It should be pointed out that there do not exist transitions from the
state XXX to any other state, including back to XXX.  Consequently,
there exist no corresponding transition probabilities (zero, or
otherwise).  They simply do not exist in the transition probability
matrix, which has only 24 rows, not 25.

To specify a model of a baseball team, we need to specify the 600
transition probabilities.  At least 304 of these will be zero, by the
rules.  The rest of the probabilities will fall between 0 and 1.  But
all transitions from a given state (but not XXX) add to 1, because the
game has to go somewhere from each state, including possibly back to
the same state.  Because there are 24 of these transient states, and
each has this single constraint, our models of baseball teams live in
a 272 dimensional parameter space.  (Each constraint reduces the
dimension by 1.)

To determine the values of these parameters for each team, the
simplest method uses the so-called maximum likelihood estimates
(MLEs):
$$\mbox{MLE of } p_{ij} = \frac{\mbox{number of transitions made from
    $i$ to $j$}}{\mbox{total number of transitions made from $i$}}$$
In calculating the MLEs, use game records for a particular team, if
you want a model of that team.  My team models come only from the game
records of the team batting at home.  I made this choice to make the
models as different as possible.  Even in the Major Leagues, ballparks
differ substantially, and the home field can have a significant effect
on the play.  The park effects add distinctiveness to the models that
also comes from the differences in the team at bat.  Fixing the home
field reduces variability in the data from game to game.

Unfortunately, baseball models based on MLEs have significant
drawbacks, especially when we consider the models together.  Though,
some transitions are common---for example, 0:0X occurs in most
innings---many others are not.  Many that can occur, do occur only
rarely.  Invariably, some of these rare but possible transitions will
happen for one team, in one year, but not for the other.  As a
consequence, the MLE model will enforce that certain transitions that
do happen occasionally for one team, simply cannot for the other.  The
corresponding transition probability while nonzero for the first team,
will remain zero for the second.

For example, the rare transition 23X:3X happened once in 2011 for the
Baltimore Orioles, but never in 2011 for the New York Yankees.  Thus,
if you ever see the 23X:3X transition in a long series of
half-innings, you can immediately reject, with absolute certainty, the
statement that the 2011 MLE model of the Yankees simulated the data.

Our method will still give a correct answer for the number of
half-innings needed to make this judgment correctly with the given
confidence level.  But depending on how commonly the 23X:3X
transition, and the others like it, appear for the Orioles, our model
selection can be deceptively easy for a reason that depends more on
the noise in the data than on the teams under study. Thus, the
interpretation of this result must be made in the context of this
rather unusual behavior of the MLEs for baseball.

One possible solution to the simultaneously zero and non-zero
transition probability problem, smooths the transition matrix in such
a way that no transition remains impossible for one team that stands
possible for another.  After all, if a transition truly is possible,
it should not be deemed impossible by a zero probability, even if it
never occurred for a team one year.  There exist principled ways of
making this adjustment, discussed in [Marchi \& Albert, 2013], but
they are beyond the scope of the present paper.

\section{Deciding Between Models}
Computing the number of samples needed for model selection with
confidence requires two things: (1) you must be able to simulate the
true model to generate the samples, and (2) you must be able to
calculate the likelihood of each of these sample, for both the true
model and the alternative model.  In baseball the model was a Markov
chain.  Each sample was a half-inning of the true team model batting
according to its transition probability matrix.  Simulating a
half-inning involved starting with the bases empty, no outs (the 0
state) then successively using the transition probabilities to ``throw
the dice'' to see the succession of states until reaching the XXX
state.  Each of these transitions has a probability associated with
it.  Since no player consistently bats over 0.500, most plate
appearances will lead to an out.  Teams most common inning for all
teams is 0:0X:0XX:XXX.  But sometimes teams get lucky and the dice
show more unusual things.  The likelihood of a baseball inning is the
product of its transition probabilities.  We are interested in the log
of this number.

For a simpler model, with a one-dimensional parameter space (instead
of 272 dimensions) we use the student t-distribution.  Its single
parameter is the number of degrees of freedom.  Many software packages
allow specifying an infinite number of degrees which, in turn,
specifies the standard normal distribution.  Our true model will be a
t-distribution with 5 degrees of freedom, t(5), and the alternative
model we wish to reject with confidence is the normal distribution,
N(0,1).

Analogous to a single half-inning in baseball, such as 0:0X:0XX:XXX,
each sample of the t-distribution is a single number on the real line,
either positive, zero, or negative, such as -0.143134.  Once we get
many such samples, the next step is to compute the likelihood of each
sample.  In baseball, the most likely sample was 0:0X:0XX:XXX, but
there were infinitely many with lower, sometimes much lower
likelihoods.  Likewise, for the t-distributions the most likely sample
is 0.  When likelihood is plotted, 0 is the top of a bell curve, and
away from 0, the likelihood drops off with a different shape,
depending on the number of degrees of freedom.  The lower the number
of degrees of freedom, the lower the likelihood at the most likely
value, and the higher the likelihood in the tails.

If you are deciding between t(5) and N(0,1), using one sample, you
make the choice based on which model has a higher likelihood at the
sample.  If the sample is near the center, you pick N(0,1), and if the
sample is in the tails you pick t(5).  But, even for t(5), most
samples will fall near the center, so if the true model is t(5), you
get the answer wrong, most of the time.  Only when you take many
samples, and start to fill in the histogram, with lots of samples in
the tails, are you likely to reject N(0,1).

The same phenomenon occurs in baseball modeling.  As mentioned above,
the most likely inning for all teams is 0:0X:0XX:XXX.  But for teams
that do not bat as well, 0:0X:0XX:XXX is even more likely than for
teams that have better offenses.  What this means is that if the true
team has better hitters, and you only use one inning to choose between
teams, you will likely get the answer wrong, most of the time.  It is
only when you get a long collection of innings, and start to see the
distribution of rare innings fill out, that you will have a better
chance of making the right choice.

How do you make the selection using more than one sample.  The
likelihood of each sample the probability (or, in the case of the
t-distribution, the probability density) of seeing the sample.  We
assume that samples are independent, so that their probabilites (or
probability densities) multiply.  The product of these small numbers
can be too small for a computer's floating-point precision, so we use
log-likelihood instead of log.  Log-likelihoods add.

Now we are really interested in the relative log-likelihood.

% Use BibTeX

\end{document}


